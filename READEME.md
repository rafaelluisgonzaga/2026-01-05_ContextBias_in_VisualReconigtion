
![Context Bias in Visual Recognition](cover/IMAGE.png)
# Context Bias in Visual Recognition
## Human-in-the-Loop Learning with Controlled Semantics

Este projeto investiga **como modelos de Machine Learning aprendem (ou falham em aprender) conceitos visuais**, demonstrando de forma prÃ¡tica o impacto de:
- ausÃªncia de semÃ¢ntica,
- semÃ¢ntica contextual leve,
- vazamento de informaÃ§Ã£o (label leakage),
- e feedback humano no loop de aprendizado.

O foco **nÃ£o Ã© maximizar acurÃ¡cia**, mas **compreender o comportamento do modelo**, seus erros e atalhos.

---

## ðŸŽ¯ Objetivo

Demonstrar que:

1. Features visuais simples (ex: brilho) sÃ£o insuficientes para discriminar cidades.
2. SemÃ¢ntica externa **nÃ£o-identificadora** melhora o desempenho e a estrutura do erro.
3. VariÃ¡veis altamente identificadoras produzem resultados ilusÃ³rios (leakage).
4. Feedback humano pode ser usado para **ajuste qualitativo**, nÃ£o apenas mÃ©trico.

---

## ðŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw/                 # imagens organizadas por cidade
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ dataset.csv
â”‚   â”‚   â””â”€â”€ feedback.csv
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ preprocess.py        # extraÃ§Ã£o de features
â”‚   â”œâ”€â”€ train.py             # treino do modelo
â”‚   â”œâ”€â”€ evaluate.py          # avaliaÃ§Ã£o Top-K
â”‚   â””â”€â”€ app.py               # interface human-in-the-loop
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ§  Dados

- 8 cidades europeias
- 20 imagens por cidade
- Total: **160 imagens**
- Imagens reais, sem data augmentation

---

## ðŸ”§ Features Utilizadas

### Baseline
- `brightness`: brilho mÃ©dio da imagem

Resultado:
- AcurÃ¡cia â‰ˆ **0.06**
- PrÃ³ximo ao acaso (1/8 â‰ˆ 12.5%)

---

### Modelo com SemÃ¢ntica Leve (sem vazamento)
- `brightness`
- `region` (macro-regiÃ£o europeia)

Resultado:
- AcurÃ¡cia Top-1 â‰ˆ **0.27**
- Top-3 Accuracy = **1.00**

> Embora o modelo erre a cidade exata, a cidade correta aparece consistentemente entre as trÃªs mais provÃ¡veis.

---

## ðŸ“Š AvaliaÃ§Ã£o Correta: Top-K Accuracy

Em problemas com mÃºltiplas classes, Top-1 Ã© excessivamente rÃ­gido.

Este projeto utiliza:
- **Top-1** â†’ acerto exato
- **Top-3** â†’ aproximaÃ§Ã£o semÃ¢ntica
- **Top-5** â†’ contexto correto

Resultado observado:
```
Top-1 Accuracy: 0.27
Top-3 Accuracy: 1.00
Top-5 Accuracy: 1.00
```

---

## ðŸ‘¤ Human-in-the-Loop

O projeto inclui uma interface interativa onde:

1. O modelo apresenta Top-3 hipÃ³teses
2. O humano escolhe a cidade correta
3. O feedback Ã© salvo explicitamente

Arquivo gerado:
```
data/processed/feedback.csv
```

Cada linha contÃ©m:
```
image_path, chosen_city, true_city, correct
```

---

## ðŸ” Uso do Feedback Humano

O feedback humano **nÃ£o sobrescreve rÃ³tulos** nem treina o modelo online.

Ele Ã© utilizado para:
- anÃ¡lise qualitativa dos erros,
- identificaÃ§Ã£o de ambiguidades recorrentes,
- e possÃ­vel incorporaÃ§Ã£o futura via reponderaÃ§Ã£o.

> **â€œO feedback humano Ã© utilizado para anÃ¡lise qualitativa e pode ser incorporado ao treinamento via reponderaÃ§Ã£o de amostras, reforÃ§ando padrÃµes onde o modelo apresenta maior incerteza.â€**

Resultados observados:
- AcurÃ¡cia global permanece estÃ¡vel ou pode cair levemente
- O modelo se torna mais calibrado e menos confiante em erros

---

## ðŸ§  ConclusÃµes

- AcurÃ¡cia isolada nÃ£o reflete aprendizado real.
- SemÃ¢ntica externa ajuda apenas quando controlada.
- Vazamento de identidade gera mÃ©tricas enganosas.
- Top-K revela estrutura semÃ¢ntica aprendida.
- Feedback humano melhora qualidade interpretativa.

---

## âœ… Estado Final

O projeto Ã© **intencionalmente encerrado neste ponto**.

AvanÃ§ar para CNNs ou embeddings prÃ©-treinados alteraria a proposta central:
> compreender comportamento, nÃ£o maximizar performance.

---

## ðŸ“Œ ObservaÃ§Ã£o Final

Este projeto demonstra maturidade em Machine Learning ao:
- evitar overfitting artificial,
- priorizar interpretabilidade,
- fechar o ciclo completo: dados â†’ modelo â†’ erro â†’ humano â†’ ajuste.
"""